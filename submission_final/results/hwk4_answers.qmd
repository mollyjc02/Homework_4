---
title: "Homework 4"
subtitle: "ECON 470, Spring 2025"
author: "Molly Catlin"
format:
  pdf:
    output-file: "catlin_molly_hwk4_s2"
    output-ext:  "pdf"
    header-includes:
      - \usepackage{float}
      - \floatplacement{table}{H}
---

```{r}
#| include: false

if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, ggplot2, dplyr, lubridate, readr, readxl, hrbrthemes, fixest,
               scales, gganimate, gapminder, gifski, png, tufte, plotly, OECD,
               ggrepel, survey, foreign, devtools, pdftools, kableExtra, modelsummary,
               kableExtra) 
library(patchwork)
library(gridExtra)
```

Here is a link to my repository: {https://github.com/mollyjc02/Homework_4.git}

\newpage 
```{r}
#| include: false
#| eval: true

library(here)
load(here("submission_final", "results", "hwk4_workspace.RData"))
```


\newpage 


## 1. Remove all SNPs, 800-series plans, and prescription drug only plans (i.e., plans that do not offer Part C benefits). Provide a box and whisker plot showing the distribution of plan counts by county over time. Do you think that the number of plans is sufficient, too few, or too many? 

```{r} 
#| echo: false
#| label: fig-plan-counts
#| fig-cap: "Distribution of Plan Counts by County Over Time"

print(plan_counts_plot)
```

Figure 1 shows that most counties had around 6–7 Medicare Advantage plans available from 2011 to 2015. In 2010, this number was substantially higher (around 13), but it decreased and stabilized in the following years. Although a count of 6–7 plans per county is a substantial drop from the value received in 2010, it still offers a relatively reasonable number of options for Medicare beneficiaries to choose from. It’s also important to note the presence of high outliers, which indicate that some counties had far more plans than average. This suggests that the median number of plans may better reflect typical access, and in some counties, it could be low enough to limit meaningful choice.


\newpage 


## 2. Provide bar graphs showing the distribution of star ratings in 2010, 2012, and 2015. How has this distribution changed over time? 

```{r} 
#| echo: false
#| label: fig-star-dist
#| fig-cap: "Distribution of Star Ratings by Year"

print(star_dist_plot)
```

Generally speaking, the distribution of star ratings has shifted over time, with fewer poorly rated plans and more highly rated plans becoming available. This trend appears to be most evident when looking at the sharp decline in the number of 2.5-star plans, which made up the majority in 2010 but dropped significantly by 2012 (see Figure 2). Inversely, the number of 4.5-star plans was substantially higher in 2015 than it was in 2010.


\newpage 


## 3. Plot the average benchmark payment over time from 2010 through 2015. How much has the average benchmark payment risen over the years?

```{r} 
#| echo: false
#| label: fig-bench-plt
#| fig-cap: "Average Benchmark Payment for MA Plans (2010–2015)"

print(bench_plt)
```

The average benchmark payment remained relatively stable between 2010 and 2015, staying around $800. The only exception was a slight increase in 2014 to approximately $850, but this value returned to $800 in 2015 (see Figure 3).


\newpage 


## 4. Plot the average share of Medicare Advantage (relative to all Medicare eligibles) over time from 2010 through 2015. Has Medicare Advantage increased or decreased in popularity? How does this share correlate with benchmark payments?

```{r} 
#| echo: false
#| label: fig-adv-share
#| fig-cap: "Average Medicare Advantage Share of Medicare Eligibles (2010–2015)"

print(adv_share_plt)
```

Medicare Advantage attainment rates among all Medicare eligibles have demonstrated a positive trend from 2010 to 2015. In 2010, Medicare Advantage's share of the market was about 20% and rose to nearly 30% by 2015 (see Figure 4). This increase appears to occur independently of any shifts in benchmark payments, as those have remained stable across the time period (see Figure 3).


\newpage 



### The following questions are utilizing data from 2010 only. 


## 5. Calculate the running variable underlying the star rating. Provide a table showing the number of plans that are rounded up into a 3-star, 3.5-star, 4-star, 4.5-star, and 5-star rating.

```{r} 
#| echo: false
#| label: fig-rating
#| tbl-cap: "Number of Plans by Rounded Star Rating" 

kable(data_2010_round)

```


\newpage 


## 6. Using the RD estimator with a bandwidth of 0.125, provide an estimate of the effect of receiving a 3-star versus a 2.5 star rating on enrollments. Repeat the exercise to estimate the effects at 3.5 stars, and summarize your results in a table.

```{r} 
#| echo: false
#| label: tab-q6
#| tbl-cap: "RDD Estimates by Star Rating" 

modelsummary(models,
             statistic = "std.error",
             stars = TRUE,
             gof_omit = "Adj|Log|F|AIC|BIC", 
             output = "kableExtra") 
```


\newpage 


## 7. Repeat your results for bandwidhts of 0.1, 0.12, 0.13, 0.14, and 0.15 (again for 3 and 3.5 stars). Show all of the results in a graph. How sensitive are your findings to the choice of bandwidth? 

```{r} 
#| echo: false
#| label: fig-q7
#| fig-cap: "RDD Results Across Bandwidths" 

print(q7_fig)
```

The results are generally stable across the range of bandwidths. For the 2.5 vs. 3-stars cutoff, the estimated treatment effect remains consistently positive and statistically significant across all bandwidths, though the magnitude slightly decreases as the bandwidth widens. In contrast, the estimates for the 3 vs. 3.5-stars cutoff are small, close to zero, and statistically insignificant (with the exception of a bandwidth of 0.10). This suggests that the results observed using RDD are relatively insensitive to the choice of bandwidth.


\newpage 


## 8. Examine (graphically) whether contracts appear to manipulate the running variable. In other words, look at the distribution of the running variable before and after the relevent threshold values. What do you find?


```{r} 
#| message: false
#| warning: false
#| echo: false
#| label: fig-dist
#| fig-cap: "Variable Distribution" 

grid.arrange(dist_3, dist_35, ncol = 2, top = "Density of Running Variable")
```

The density plots show the distribution of raw plan ratings around the 2.75 and 3.25 cutoffs. In panel a, there is a clear spike just above the 2.75 threshold, suggesting a potential manipulation of scores to round plans up to a 3-star rating. In contrast, panel b shows a smoother distribution around the 3.25 threshold, with no clear discontinuity or sign of manipulation. This suggests that manipulation is more likely to occur at the lower threshold.


\newpage 


## 9. Similar to question 4, examine whether plans just above the threshold values have different characteristics than contracts just below the threshold values. Use HMO and Part D status as your plan characteristics.


```{r} 
#| echo: false
#| label: fig-balance
#| fig-cap: "Plan Characteristics" 

combined_plot <- plot_30 + plot_35 + plot_layout(ncol = 2)
print(combined_plot)
```

In both panels, the HMO characteristic shows a greater imbalance between plans above and below the star cutoff than Part D status. This means plans just above the cutoff for both 3 and 3.5 stars are more likely to differ in HMO status than in whether they offer Part D. The fact that there are observable differences in plan characteristics just above and below the rating thresholds suggests that a crucial assumption of RDD — that values around the cutoff are similar — may be a weak assumption in this case.


\newpage 


## 10. Summarize your findings from 5-9. What is the effect of increasing a star rating on enrollments? Briefly explain your results.

The results from Questions 5–9 suggest that increasing a plan’s star rating can have a meaningful impact on enrollments. The RD analysis in Question 6 showed that receiving a 3-star rating (vs. 2.5 stars) leads to a statistically significant increase in market share. In contrast, the effect of moving from 3 to 3.5 stars was small and statistically insignificant. These findings were robust across different bandwidths (Question 7), indicating that the treatment effect at the 3-star threshold is not particularly sensitive to the choice of bandwidth size.

The density plots in Question 8 suggest possible manipulation of ratings just above the 2.75 cutoff, with a visible spike in plan ratings, while the distribution near 3.25 appeared more uniform. This could potentially be due to the significant increase observed around the cutoff for 2.5 vs. 3-star plans but not for 3 vs. 3.5-star plans. Finally, in Question 9, I found that plans just above the cutoff were different in observable characteristics—particularly HMO status—suggesting that RDD assumptions may be weaker around the 3-star threshold. Despite this limitation, taken together, these results highlight that 3 stars is a meaningful policy threshold for Medicare Advantage plans, which may incentivize manipulative behavior to obtain that rating.
